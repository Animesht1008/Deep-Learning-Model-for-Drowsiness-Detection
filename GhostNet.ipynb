{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, BatchNormalization, ReLU, DepthwiseConv2D, Concatenate, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghost_module(inputs, filters, kernel_size=(3, 3), ratio=2):\n",
    "    init_channels = int(filters / ratio)\n",
    "    new_channels = int(filters - init_channels)\n",
    "\n",
    "    # Primary Convolution\n",
    "    x = Conv2D(init_channels, kernel_size, strides=(1, 1), padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Cheap Operation\n",
    "    cheap = DepthwiseConv2D(kernel_size, strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    cheap = BatchNormalization()(cheap)\n",
    "    cheap = ReLU()(cheap)\n",
    "\n",
    "    # Concatenating the outputs\n",
    "    cheap = Conv2D(new_channels, (1, 1), strides=(1, 1), padding='same', use_bias=False)(cheap)\n",
    "    cheap = BatchNormalization()(cheap)\n",
    "    cheap = ReLU()(cheap)\n",
    "\n",
    "    x = Concatenate()([x, cheap])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GhostNet(input_shape=(224, 224, 3), classes=2):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Initial Layer\n",
    "    x = Conv2D(16, (3, 3), strides=(2, 2), padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Example of applying Ghost Modules\n",
    "    x = ghost_module(x, 16)\n",
    "    # ... Continue building the network with more Ghost modules and other necessary layers\n",
    "\n",
    "    # Final Layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GhostNet(input_shape=(224, 224, 3), classes=1)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with your data\n",
    "# history = model.fit(train_generator, epochs=10, validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2149 images belonging to 2 classes.\n",
      "Found 272 images belonging to 2 classes.\n",
      "Found 268 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths to your dataset\n",
    "train_data_dir = './train/'\n",
    "test_data_dir = './test/'\n",
    "val_data_dir = './val/'\n",
    "\n",
    "# Set parameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'  # assuming binary classification (drowsy and non-drowsy)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=10, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
